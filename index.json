[{"content":"モチベーション 普段私は仕事でgitlab を使っているのだが、jarのビルドに手間取った。ビルドするだけならgradle buildすればできるが、最近はそれだけじゃなくて色々な形式でartifactを出したり、キャッシュを使ってスピードアップなどしたりちょっと使いこなそうとしているためである。使ってみると意外と便利だが、記事が散らばっていて大変だったので、とりあえずこれやっとけば全部出るぞってのをまとめた。めんどくせえという人はソース本体を見てね。\nGitLabのArtifactのReportタイプについて ↓原文はこちら\nhttps://docs.gitlab.com/ee/ci/yaml/artifacts_reports.html\nartifacts:reports:coverage_report マージリクエストを出したときにここはテストされてる、されてないみたいなことを出してくれる。便利だー。gitlab 13系以前では、artifacts:repots:coberturaというふうに書いてねとあったが、肝心のcoberturaが2023年2月現在、開発がストップしてることもあって、14系で非推奨になり、15系からは上記のようになった。デファクトはJacocoであり、Jacocoからcobertura形式には変換をかけなくてはいけないので、それは後述する。\n引用: https://docs.gitlab.com/ee/ci/testing/code_quality.html\nartifacts:reports:codequality マージ先のブランチとマージ元のブランチでそれぞれcodequality形式で出しておくと、何が良くなって何が悪くなったかをマージリクエスト上で確認できる。プレミアムなど使うとマージリクエストの差分上で確認できる。あくまでも差分しか出てこないので、全量を見るにはhtml形式のレポートをgitlab pagesなどに出しておく必要がありそう。 artifacts:reports:junit Junitでテストした時に出てくる。こういうふうに指定してあげれば大丈夫だと思う。\nartifacts: when: always #失敗時もレポートがartifactsから取れるように reports: junit: ${CI_PROJECT_DIR}/build/test-results/test/**/TEST-*.xml パイプライン上にテストの結果がまとまるので、どこでエラーが壊れたかなどが追える意味でも出しておけばいいと思う。 https://docs.gitlab.com/ee/ci/testing/unit_test_reports.html\njacoco形式からcoberturaの変換について 下記のイメージを使って変換すると公式に書いてある。 https://docs.gitlab.com/ee/ci/testing/test_coverage_visualization.html#gradle-example\nhttps://gitlab.com/haynes/jacoco2cobertura\nもちろんjacocoReportを出してからじゃないといけない。そのためjarをUploadするジョブと並列に実行すればいいと思っている。またこのジョブでjacocoReportからGitLabのカバレッジに食わせるためにカバレッジを獲得して渡している。そうするとマージリクエスト上にソースコード全体のカバレッジ率やAnalitics/Repositoryからのカバレッジ率が見えるようになる。\nconvert-to-cobertura: stage: upload image: haynes/jacoco2cobertura:1.0.7 variables: JACOCO_REPORT_PATH: build/reports/jacoco/test/jacocoTestReport.xml dependencies: - stest script: # for xmllint - apk --no-cache add libxml2-utils - python /opt/cover2cover.py $JACOCO_REPORT_PATH $CI_PROJECT_DIR/src/main/java/ \u0026gt; build/reports/coverage.xml - covered=$(xmllint --xpath \u0026#39;string(/report/counter[@type=\u0026#34;BRANCH\u0026#34;]/@covered)\u0026#39; $JACOCO_REPORT_PATH) - missed=$(xmllint --xpath \u0026#39;string(/report/counter[@type=\u0026#34;BRANCH\u0026#34;]/@missed)\u0026#39; $JACOCO_REPORT_PATH) - coverage=$(awk -vmissed=$missed -vcovered=$covered \u0026#39;BEGIN{ printf(\u0026#34;%.1f\\n\u0026#34;, covered/(covered+missed)*100 ) }\u0026#39;) - echo \u0026#34;Test Coverage=${coverage}%\u0026#34; coverage: \u0026#39;/Test Coverage=\\d+\\.\\d+/\u0026#39; allow_failure: true artifacts: reports: coverage_report: coverage_format: cobertura path: build/reports/coverage.xml 参考: https://kiririmode.hatenablog.jp/entry/20220402/1648889452\ncheckstyleレポートからcodequality形式の変更について gradle のプラグインでやる方法があったので参考にした。codeclimate形式で出すときはこれはディレクトリがないと失敗するみたいなので、気をつけること。\n2023/03/05追記: 対応されました。https://github.com/tomasbjerre/violations-gradle-plugin/issues/21\nplugins { id \u0026#34;se.bjurr.violations.violations-gradle-plugin\u0026#34; version \u0026#34;1.52.3\u0026#34; } task violations(type: se.bjurr.violations.gradle.plugin.ViolationsTask) { codeClimateFile = file(\u0026#39;build/reports/codequality.json\u0026#39;) // Will create a CodeClimate JSON report.  violations = [ [\u0026#34;CHECKSTYLE\u0026#34;, projectDir.path, \u0026#34;.*/checkstyle/.*\\\\.xml\\$\u0026#34;, \u0026#34;Checkstyle\u0026#34;], ] } jacocoTestReport.dependsOn(test) checkstyleMain.finalizedBy violations checkstyleTest.finalizedBy violations 参考: https://www.gitlab.jp/blog/2021/12/04/lightweight-codequality/\nソース本体 https://gitlab.com/lottotto/my-jar-build-pipeline/-/blob/main/.gitlab-ci.yml https://gitlab.com/lottotto/my-jar-build-pipeline/-/blob/main/build.gradle\nまとめると  いい感じに出すことができたと思う。 gitlab側が頑張ってこういう機能入れてるから使ってあげないとね。 gradle のプラグインだったり、変換くんに関しては便利だけどいつまで保守されるかわからないなー。  ","permalink":"https://www.lottohub.jp/posts/build-jar-gitlab/","summary":"モチベーション 普段私は仕事でgitlab を使っているのだが、jarのビルドに手間取った。ビルドするだけならgradle buildすればできる","title":"gitlabでカバレッジ, Junit, codequalityのartifactsを全部出す"},{"content":"この記事について まだOpenTelemetryのログに対しては仕様が固まっていない状況だが、情報がまとまっていないのでいろいろGithub見てまとめてみることを目的としている。\nロギングとは wikipedia によると下記のように書かれています\n In computing, a log file is a file that records either events that occur in an operating system or other software runs, or messages between different users of a communication software.　Logging is the act of keeping a log. https://en.wikipedia.org/wiki/Logging_(software)\n コンピューティングでは、ログファイルとは、OSや他のソフトウェアが稼働するときに発生するイベント,またはコミュニケーションソフトウェアでの異なるユーザ間でのメッセージを記録するファイルである。ロギングとはログを保持する行為であるといいます。\nログの目的 上記のログの定義や私個人の経験からログの目的については主に下記の4つが考えられます\n システムのイベントをログから解読し、稼働中か開発中のソフトウェアの障害根本原因を分析するために利用する 法律対応などの背景をもとにソフトウェアが提供する機能の一つとして、データの操作の監査証跡として利用する ログを集計することで、ソフトウェアのメトリックを出したり、レイテンシを出したりするためのプロファイルとして利用する ログを統計分析することで、実行しているユーザの動作やエラーの予防検知などの状態予想などに利用する  ログのベストプラクティス 上記の目的を達成するためにはどのようなログのベストプラクティスが必要なのかを考えていきます。それと私なりの解釈を書いておきます\n ログライブラリを利用すること\n自前でprintfするのは管理が厳しくなるのでやめましょうという話。ベストプラクティスの前の基本動作. javaだったらlogbackだったり、goだったらzapだったり、いろいろ存在する。\nただしlog4jのようなログライブラリへのバグが見つかるケースもあるので注意しておこう 適切なレベルでログを記録すること\ninfoがなにとか、error が何とかはこちらを参照すること。https://ja.wikipedia.org/wiki/Log4j いつも悩むINFOレベルの具体的なケースとしては、サービスにアクセスされたときの開始/終了情報, サービスから他のサービスやDBにアクセスしに行った時の開始/終了情報とかになるのかなぁ。\nWARNについては、例えばDBのアクセスが遅くなったり、キャッシュができなかった時に出すのがよくあるパターンっぽい 適切なログのカテゴリを指定すること\nログを出すときにカテゴリを指定する。例えばモジュールごとだったり、DBのアクセスだったり、監査要件を満たす内容だったりでカテゴリつけると追うのが楽になるはず。 意味のあるログメッセージを出力すること\nsession startとかだけだと何にもわからないので、意味のあるログメッセージを出しておく。運用側の意見が欲しいのでこことか聞いてみるとDevOpsになっていいかも。 ログメッセージは英語で記載すること\nあたりまえ体操 ログメッセージにはコンテキスト情報を記載すること\ntransaction start とかにもcontext情報を付加して、transaction ID: 1qazxsw2 startとかつけるとよりわかりやすくなる。 プログラムが解析しやすいフォーマットでログを出すこと\n構造化しとけ 同時に人間も読めるログのフォーマット形式にすること\n障害分析するのは人間なんだから機械によめるだけじゃなくて人間にも読みやすくしようね。最近はjsonで出すのがトレンド ログに出す量は多すぎても、少なすぎてもいけないこと\nといわれてもぶっちゃけ何取ればいいかわからん。そういう時は開発中はとりあえずログ出しておいて、運用しながら減らせばいい。簡単に減らせるようなアプリの作りにしておく ログを利用する人のことを考えること\n後日読む人は開発者じゃない。他人のことを考えてログを出そう ログを障害分析のためだけに使わないこと\n監査だったり、プロファイラだったり、統計利用だったりする。とくに統計分析とかは手段が目的化しやすいので、分析して何したいのとかを決めておくこと。 ベンダーロックインを避けること\nlog4jとかでバグ見つかるから、ログのライブラリのロックインはきをつけよう。 センシティブな情報をログに出さないこと\nクレカ番号などの個人情報出ると事業おわるよ。  参考: https://www.dataset.com/blog/the-10-commandments-of-logging/\nOpenTelemetryのログの現状 2022年5月現在のOpenTelemetryとしては、下記の状態。https://opentelemetry.io/status/ API: draft SDK: draft Protocol: beta ログのデータモデルとしては実験的だが定義されている様子。APIやSDKなどすべてstableになるのは2~3年以上かかると考えました。 https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/logs/data-model.md 参考:https://event.cloudnativedays.jp/o11y2022/talks/1347\nデータモデル 現在Opentelemetryが例示しているログレコードのフィールドは下記の通り\n   Field Name Description     Timestamp Time when the event occurred.   ObservedTimestamp Time when the event was observed.   TraceId Request trace id.   SpanId Request span id.   TraceFlags W3C trace flag.   SeverityText The severity text (also known as log level).   SeverityNumber Numerical value of the severity.   Body The body of the log record.   Resource Describes the source of the log.   InstrumentationScope Describes the scope that emitted the log.   Attributes Additional information about the event.    特によくわからない、Resourceについては、ログを出しているPodの名前だったり、service名だったり、バージョンだったり、IPアドレスだったりが該当する。またAttributesについては例えばHTTP上の情報などが該当する。より具体的には、UserAgentや、Statusコード、HTTPのパスなどが該当する。 上記の内容をベストプラクティスに従い、プログラムで読みやすく構造化して記録すると下記のようになる\n{ \u0026#34;Timestamp\u0026#34;: \u0026#34;1586960586000000000\u0026#34;, \u0026#34;Attributes\u0026#34;: { \u0026#34;http.scheme\u0026#34;:\u0026#34;https\u0026#34;, \u0026#34;http.host\u0026#34;:\u0026#34;donut.mycie.com\u0026#34;, \u0026#34;http.target\u0026#34;:\u0026#34;/order\u0026#34;, \u0026#34;http.method\u0026#34;:\u0026#34;post\u0026#34;, \u0026#34;http.status_code\u0026#34;:500, \u0026#34;http.flavor\u0026#34;:\u0026#34;1.1\u0026#34;, \u0026#34;http.user_agent\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\u0026#34;, }, \u0026#34;Resource\u0026#34;: { \u0026#34;service.name\u0026#34;: \u0026#34;donut_shop\u0026#34;, \u0026#34;service.version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;k8s.pod.uid\u0026#34;: \u0026#34;1138528c-c36e-11e9-a1a7-42010a800198\u0026#34;, }, \u0026#34;TraceId\u0026#34;: \u0026#34;f4dbb3edd765f620\u0026#34;, // this is a byte sequence  // (hex-encoded in JSON)  \u0026#34;SpanId\u0026#34;: \u0026#34;43222c2d51a7abe3\u0026#34;, \u0026#34;SeverityText\u0026#34;: \u0026#34;INFO\u0026#34;, \u0026#34;SeverityNumber\u0026#34;: 9, \u0026#34;Body\u0026#34;: \u0026#34;20200415T072306-0700 INFO I like donuts\u0026#34;, } ベストプラクティスとの対応状況考察 このログレコードや将来Opentelemetryでログを実装することを考えた時、ベストプラクティスを達成しているかどうかについて考察してみる\n   ベストプラクティス 達成度 根拠     1. ログライブラリを利用すること 達成 今はまだないけどOpentelemetryのライブラリを使うはずなのでできる   2. 適切なレベルでログを記録すること 未達成 ソフトウェアの作りに依存するため判断不可能   3. 適切なログのカテゴリを指定すること 達成 Resource等にカテゴリ情報を記載することで可能   4. 意味のあるログメッセージを出力すること 未達成 ソフトウェアの作り次第   5. ログメッセージは英語で記載すること 達成 ソフトウェアの作り次第だが流石に大丈夫でしょう   6. ログメッセージにはコンテキスト情報を記載すること 達成 Opentelemetryでトレースがあるのでそれを出すだけだと思う   7. プログラムが解析しやすいフォーマットでログを出すこと 達成 JSONで構造化している   8. 同時に人間も読めるログのフォーマット形式にすること 達成 人間読めると思うし、jqでbodyだけ出せば…。改行が重要かな   9. ログに出す量は多すぎても、少なすぎてもいけないこと 未達成 ソフトウェアの作り次第   10. ログを利用する人のことを考えること 未達成 ソフトウェアの作り次第   11. ログを障害分析のためだけに使わないこと 達成 運用側次第だが、障害分析以外にも使える準備はできてる   12. ベンダーロックインを避けること 達成 Opentelemetryの考え方がベンダロックイン防止   13. センシティブな情報をログに出さないこと 未達成 ソフトウェアの作り次第    ということで、Opentelemetryのフォーマットに従うだけで、8/13は達成しているのかなと思われる。\nOpentelemetryのログ対応を代わりにzapで実装してみる では上記のログレコードの形式で実装することで、結構ベストプラクティスを満たせそうなのでZapの練習がてらにやってみることとする。\nZapの初期設定に関しては下記の通り。Qiitaなどに記事が載っているのでそちらを参考にしました。ポイントとしては特にありません。KeyをOpentelemetryが現在提唱しているフォーマットに変えたくらいです。 参考: https://qiita.com/emonuh/items/28dbee9bf2fe51d28153\npackage logger import ( \u0026#34;context\u0026#34; \u0026#34;go.opentelemetry.io/otel/trace\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; ) func GetZapLogger() (*zap.Logger, error) { level := zap.NewAtomicLevel() level.SetLevel(zapcore.DebugLevel) cfg := zap.Config{ Level: level, Encoding: \u0026#34;json\u0026#34;, EncoderConfig: zapcore.EncoderConfig{ TimeKey: \u0026#34;TimeStamp\u0026#34;, LevelKey: \u0026#34;SeverityText\u0026#34;, NameKey: \u0026#34;Name\u0026#34;, CallerKey: \u0026#34;Caller\u0026#34;, MessageKey: \u0026#34;Body\u0026#34;, EncodeLevel: zapcore.CapitalLevelEncoder, EncodeTime: zapcore.ISO8601TimeEncoder, EncodeDuration: zapcore.StringDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, }, OutputPaths: []string{\u0026#34;stdout\u0026#34;, \u0026#34;/tmp/zap.log\u0026#34;}, } logger, err := cfg.Build() if err != nil { return nil, err } return logger, nil } 上のloggerを呼び出すところは下記の通り\nfunc main() { zaplogger, err := logger.GetZapLogger() if err != nil { panic(err) } ... zaplogger.Info( fmt.Sprintf(\u0026#34;server listening at %v\u0026#34;, lis.Addr()), logger.GetOtelLogMetadataFields(context.Background())..., ) } func GetOtelLogMetadataFields(ctx context.Context) []zap.Field { spanContext := trace.SpanContextFromContext(ctx) traceID := spanContext.TraceID().String() spanID := spanContext.SpanID().String() return []zap.Field{ zap.String(\u0026#34;TraceId\u0026#34;, traceID), zap.String(\u0026#34;SpanId\u0026#34;, spanID), zap.Any(\u0026#34;Resource\u0026#34;, map[string]interface{}{ \u0026#34;service.version\u0026#34;: \u0026#34;1.0.0\u0026#34;, }), zap.Any(\u0026#34;Attribute\u0026#34;, map[string]interface{}{ \u0026#34;http.scheme\u0026#34;: \u0026#34;http\u0026#34;, }), } } ポイントとしては、zapはnamespaceを利用することでログを階層化できるのだが、同じレベルでの階層を2つ作ることができない。\n参考: https://github.com/uber-go/zap/issues/351\nそのため上記Issueに書いてあるようにZap.Anyを使用して同じレベルでの階層化を実現した。\nまたspanはContextから獲得できたので、そこからSpanIDやTraceIDを獲得して、ログに出すことにした。 本当はAttributeなども取ってきたかったのだが、取ってくることができなかった\u0026hellip;。 ReadOnlySpanとかから取得しているようなのですが、そのReadOnlySpanがどのように獲得されるかがわからず。。。\n以上の結果結果下記の通りにログが得ることができました。\n{ \u0026#34;SeverityText\u0026#34;:\u0026#34;INFO\u0026#34;, \u0026#34;TimeStamp\u0026#34;:\u0026#34;2022-05-03T04:16:33.474Z\u0026#34;, \u0026#34;Caller\u0026#34;:\u0026#34;server/server.go:105\u0026#34;, \u0026#34;Body\u0026#34;:\u0026#34;server listening at [::]:50051\u0026#34;, \u0026#34;TraceId\u0026#34;:\u0026#34;00000000000000000000000000000000\u0026#34;, \u0026#34;SpanId\u0026#34;:\u0026#34;0000000000000000\u0026#34;, \u0026#34;Resource\u0026#34;:{ \u0026#34;service.version\u0026#34;:\u0026#34;1.0.0\u0026#34; }, \u0026#34;Attribute\u0026#34;:{ \u0026#34;http.scheme\u0026#34;:\u0026#34;http\u0026#34; } } 今後の改善ポイントとして、context.Contextをlogの引数に加えることと、Attributeの出力あたりでしょうか？気が向けばヘルパーみたいなの作ってみます。\nまたOpenTelemetryでログを対応するためにはOpenTelemetyかなんかでTraceを実装しておくことが前段のステップかなと思っています。その準備をしておけ場いいのかなと思います。\n","permalink":"https://www.lottohub.jp/posts/opentelemetry-zap/","summary":"この記事について まだOpenTelemetryのログに対しては仕様が固まっていない状況だが、情報がまとまっていないのでいろいろGithub見","title":"OpenTelemetryのログ仕様をZAPで実装してみる"},{"content":"Go言語の排他制御について 排他制御とは、マルチスレッドで同じ変数を参照しているとき、どっちも書き込もうとしたら変更が衝突して意図していない結果が得られることである。 そのためには、変数をロックしておくことが必要になる。実現方法としては、syncパッケージの中のMutexを利用することである。 https://pkg.go.dev/sync\nmutex mutexは相互排他ロックのことをいいます。mutexの0値は、ロック解除されたことを示します。 mutexは、最初の使用後にコピーしてはなりません。\ntype Mutex struct { state int32 sema uint32 } この構造体に対して2つのメソッドが定義されています。Lock()とUnlock()です。それぞれ、一つしかない変数など排他制御の仕組みを利用してロック状態、非ロック状態を定義しています。 実際の使用例はTour of Go のWebCraelerになります。\n↓コード全体\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Fetcher interface { Fetch(url string) (body string, urls []string, err error) } type Result struct { // 追加。なぞったかどうかを覚えておくスライスを定義 \t// 排他制御の情報を持っておく、mu変数を定義 \tresultMap map[string]bool mu sync.Mutex } func (rm *Result) isCrawled(url string) bool { // sync.Mutexを更新するので、ポインタレシーバーを利用する \t// すでに閲覧したかどうかを確認する。まずはロックをする \trm.mu.Lock() defer rm.mu.Unlock() if _, ok := rm.resultMap[url]; ok { return true } else { rm.resultMap[url] = true return false } } // すべてのGoRoutineが完了するまでまつ var wg sync.WaitGroup func Crawl(url string, depth int, fetcher Fetcher, resultMap *ResultMap) { defer wg.Done() //Crawlの処理が終わったら、WaitGroupの待機数を減らす \tif depth \u0026lt;= 0 { return } if resultMap.isCrawled(url) { return } else { body, urls, err := fetcher.Fetch(url) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026#34;found: %s %q\\n\u0026#34;, url, body) for _, u := range urls { wg.Add(1) // goRoutineに流す前にまずはWaitGroupを増やす \tgo func(u string) { Crawl(u, depth-1, fetcher, resultMap) // L38あたりのwg.Doneでwgは減らされる \t}(u) } } return } func main() { // resultMap := \u0026amp;ResultMap{} \tresultMap := \u0026amp;Result{resultMap: make(map[string]bool)} wg.Add(1) // 最初のgoroutineに流すので、まずは1つ増やす \tgo Crawl(\u0026#34;https://golang.org/\u0026#34;, 4, fetcher, resultMap) wg.Wait() // すべてのWaitGroupがなくなるまでまつ } // // fakeFetcher is Fetcher that returns canned results. type fakeFetcher map[string]*fakeResult type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) (string, []string, error) { if res, ok := f[url]; ok { return res.body, res.urls, nil } return \u0026#34;\u0026#34;, nil, fmt.Errorf(\u0026#34;not found: %s\u0026#34;, url) } var fetcher = fakeFetcher{ \u0026#34;https://golang.org/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;The Go Programming Language\u0026#34;, []string{ \u0026#34;https://golang.org/pkg/\u0026#34;, \u0026#34;https://golang.org/cmd/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Packages\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/cmd/\u0026#34;, \u0026#34;https://golang.org/pkg/fmt/\u0026#34;, \u0026#34;https://golang.org/pkg/os/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/fmt/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Package fmt\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/pkg/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/os/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Package os\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/pkg/\u0026#34;, }, }, } func (rm *Result) isCrawled(url string) bool { // sync.Mutexを更新するので、ポインタレシーバーを利用する \t// すでに閲覧したかどうかを確認する。まずはロックをする \trm.mu.Lock() defer rm.mu.Unlock() if _, ok := rm.resultMap[url]; ok { return true } else { rm.resultMap[url] = true return false } } mutexは1つのGoroutineがアクセスできるような情報を持つらしく、これによって、resultにもアクセスできなくなるっぽい。（つまり読み取れなくなる。） もし、resultMapの中にurlがあればすでに巡回済身として、trueを戻し、そうじゃなかったら、巡回リストに書き込み、falseを戻す。\nvar wg sync.WaitGroup func Crawl(url string, depth int, fetcher Fetcher, resultMap *ResultMap) { defer wg.Done() //Crawlの処理が終わったら、WaitGroupの待機数を減らす \tif depth \u0026lt;= 0 { return } if resultMap.isCrawled(url) { return } else { body, urls, err := fetcher.Fetch(url) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026#34;found: %s %q\\n\u0026#34;, url, body) for _, u := range urls { wg.Add(1) // goRoutineに流す前にまずはWaitGroupを増やす \tgo func(u string) { Crawl(u, depth-1, fetcher, resultMap) // L38あたりのwg.Doneでwgは減らされる \t}(u) } } return } func main() { // resultMap := \u0026amp;ResultMap{} \tresultMap := \u0026amp;Result{resultMap: make(map[string]bool)} wg.Add(1) // 最初のgoroutineに流すので、まずは1つ増やす \tgo Crawl(\u0026#34;https://golang.org/\u0026#34;, 4, fetcher, resultMap) wg.Wait() // すべてのWaitGroupがなくなるまでまつ } Crawl関数については、関数終了時にWaitGroupを減らす処理を入れている。そもそもWaitGroupとは、すべてのGoroutineが終了するまで待つ、といった制御が可能になるものである。 wg.Addやwg.Doneを入れる場所を間違えるとうまくいかないので注意すること。（特に再帰して関数を呼び出す場合）\nまとめ  Goroutineを利用したマルチスレッドプログラムで共通の変数を更新にかかるときは、syncパッケージによるmutexを利用する。Lockメソッドを使うことで、(おそらく同階層にある変数に対して)そのロックしたGoRoutineしかアクセスできなくなり、UnlockされるまでアクセスしようとするGoroutineは待つことになる。 多数のGoroutineを利用する際は、WaitGroupを利用してすべてのGoroutineの処理を待つことができる。wg.Doneやwg.addを入れるタイミングはとても重要。  ","permalink":"https://www.lottohub.jp/posts/go-mutex/","summary":"Go言語の排他制御について 排他制御とは、マルチスレッドで同じ変数を参照しているとき、どっちも書き込もうとしたら変更が衝突して意図していない結","title":"Go言語の排他制御について"},{"content":"Go言語のポインタについて アドレスとは アドレスとは、変数の内容が保存されるメモリの場所を示す16進数の値である。変数名の前に\u0026amp;をつけることでアドレスを提供する.このように定義された変数をポインタ変数という\na := \u0026#34;aaaa\u0026#34; b := \u0026amp;a // bはポインタ変数になる ポインタとは 仕組みとしてはアドレスが格納されているポインタ変数に対して、*をつけることで、アドレスの中身にアクセスすることができる。ポインタとは、格納されている値の型情報とアドレスから成り立っている.\na := \u0026#34;aaaa\u0026#34; b := \u0026amp;a // bはポインタ変数になる fmt.Println(*b)　// これでaaaaと出力される。 ポインタのメリット ポインタを利用することで参照渡しが実現できる。参照渡しとは、アドレスを渡すことで変数自体を渡すことである。参照私に対する言葉として値渡しがあるが、値渡しとは、変数の中身をコピーして関数にわたしていることになる。 C言語などと異なり、ポインタに対しての加算はできないので気をつけること。\npackage main import \u0026#34;fmt\u0026#34; func incrementPassByValue(i int) { i = i + 1 fmt.Println(i) } func incrementPassByReference(i *int) { i = i + 1 //ポインタの加算はできないので注意すること \tfmt.Println(i) } func main() { i := 100 fmt.Println(i) // 100 \tincrementPassByValue(i) // 101 \tfmt.Println(i) // 100 \tincrementPassByReference(\u0026amp;i) // 101、、と行きたいところだがコンパイルできない。 \tfmt.Println(i) // 101  } ポインタレシーバとは ではポインタとして変数を変えたいときはどうするべきか。これはポインタレシーバを利用するのが良いと思う\npackage main import \u0026quot;fmt\u0026quot; type Person struct { Age int Name string } func (p Person) increment() { p.Age = p.Age + 1 } func (p *Person) incrementByReference() { p.Age = p.Age + 1 } func main() { person := \u0026amp;Person{Age: 24, Name: \u0026quot;田中太郎\u0026quot;} person.increment() fmt.Println(person.Age) // 24のまま person.incrementByReference() fmt.Println(person.Age) // 25になる } まとめ 中のメソッドを更新するときはPointerレシーバーを使おう。\n","permalink":"https://www.lottohub.jp/posts/go-pointer/","summary":"Go言語のポインタについて アドレスとは アドレスとは、変数の内容が保存されるメモリの場所を示す16進数の値である。変数名の前に\u0026amp;をつけ","title":"Goのポインタについて"},{"content":" Goroutine Goのランタイムに管理される軽量なスレッドになる。スレッド数やメモリ管理などは、Goがよしなにやってくれるのでそこまで気にしなくても大丈夫（らしい）\ngo func(x,y)という形で宣言することで、別スレッドで関数を実施できる。mainのGoroutineから外れて、別スレッドに渡される。サンプルは下記の通りになる。  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { go func() { // 別goroutine に渡されて、実行される \tfmt.Println(\u0026#34;Hello Goroutine\u0026#34;) }() fmt.Println(\u0026#34;Hello Main\u0026#34;) time.Sleep(1 * time.Second) } 実行結果。別のGorutineで実行されているので、Hello Goroutineが先に帰ってくるかもしれない\n% go run main.go Hello Main Hello Goroutine  Channel チャネルオペレータの \u0026lt;- を用いて値の送受信ができる通り道です。この通り道というのはGoroutineとGoroutineを繋ぐという意味での通り道です。下記のように値を送ったり、受信したりすることができる。channelの値格納ポリシーは先入先出であるので、キューとして利用することができる。  ch \u0026lt;- v // channelへvを送信 v := \u0026lt;- ch // channelから受信したものをvという変数にする channelの定義は下記の通りにできる。２番面の引数は channelをバッファとして利用する際に必要で、格納できる値の個数となる。バッファサイズのデフォルトは0となっており、goroutineでchannelに値を送信後、受信するまでデットロック状態になります。\nch := make(chan int, 100) channelは開いているか閉じているか、の状態を持っています。これによりfor文などでの対応が可能\nv, ok := \u0026lt;- ch package main import ( \u0026#34;fmt\u0026#34; ) func fibonacci(n int, c chan int) { x, y := 0, 1 for i := 0; i \u0026lt; n; i++ { c \u0026lt;- x x, y = y, x+y } close(c) } func main() { c := make(chan int, 10) go fibonacci(cap(c), c) // cap関数でchannelのサイズを取得できる \tfor i := range c { // channelがクローズになるまで待ち続ける \tfmt.Println(i) } } 基本的な使い方としてはこれで大丈夫だと思う。適宜mutexを利用した排他制御なども見てください\n","permalink":"https://www.lottohub.jp/posts/goroutines/","summary":"Goroutine Goのランタイムに管理される軽量なスレッドになる。スレッド数やメモリ管理などは、Goがよしなにやってくれるのでそこまで気にしなくても大丈夫","title":"今更ながらGo Routineを勉強する"},{"content":"モチベーション Go言語のOpentelemetryで適当なアプリにトレーシング機能をInstrumentation（計装）した際に、分割して色々なものは対応していたのだが、まとめてやってみたというものがなく、結構苦戦したので忘備録がてら残しておこうと思う。ソースコード全量はGithubにPushしているので面倒な解説はいらねえ！という人はこちらをみてください。 https://github.com/lottotto/gRPC-Database-sample-app/tree/7f4d8f91d0c5d5a675d49e18a058c470d9b34973\nトレースしたいシステム クライアントからgRPC GateWayにhttpで送られたものがgRPC通信でgRPCサーバに転送。gRPCサーバがPostgresにSQLを実行する流れを確認したい。ただしフォーカスとしてはgRPC GateWayからとする。 クライアントからは/に対してbodyに{\u0026quot;name\u0026quot;: message} の形式のJSONをPostすることで、データベースにその内容がINSERTされる。またクエリパラメータにそのnameを付与してGETで送ることで、そのnameを持つ行全てを戻す。\n実装のポイント クライアント側 標準ライブラリを用いたhttpサーバの構成方法は他の記事に譲るとして、、、\n TraceProviderの追加  TracerProvider provides access to instrumentation Tracers. TracerProviderとはTracerへのアクセスを提供する。TracerとはStartメソッドを持つInterfaceであり、contextとNameを引数にSpanとContextを作成する機能を持つ。もしこのcontextの中にSpanがあればその子spanとして作成される\n参考:\nhttps://pkg.go.dev/go.opentelemetry.io/otel/trace#TracerProvider https://pkg.go.dev/go.opentelemetry.io/otel/trace#Tracer\nTracerProviderへの追加はプロセスセーフではないといけないので、main関数の中でかくこと。間違ってもhandlerとか多数のスレッドで呼び出されるところでやってはいけない。 後続のサービスへspanのContextを伝播するには、otel.SetTextMapPropagatorを追記すること。これはリクエスト送る側だけではなく、受け取る側にも必要\npackage main import ( \u0026#34;github.com/lottotto/stdgrpc/utils\u0026#34; \u0026#34;go.opentelemetry.io/otel\u0026#34; \u0026#34;go.opentelemetry.io/otel/propagation\u0026#34; ) func main() { // トレースの追加 \ttp, err := utils.InitTraceProviderStdOut(\u0026#34;gRPC\u0026#34;, \u0026#34;1.0.0\u0026#34;) otel.SetTracerProvider(tp) // 後続のサービスにつなげるためにpropagaterを追加 \totel.SetTextMapPropagator( propagation.NewCompositeTextMapPropagator( propagation.TraceContext{}, propagation.Baggage{}, ), ) .... }  gRPCインターセプタの追加  gRPCで後続のサービスにリクエストを送るので、gRPCのインターセプタを利用して、gRPCの情報などをtraceの値に入れる。もちろん後続へspanを教えるためにこのメソッドは必要。 grpc.WithUnaryInterceptorを利用し、opentelemetryのUnary通信用のインターセプタを入れる。複数Interceptorを入れる場合はChain何ちゃらを使うこと。 （おまけ）gRPCのコネクションをプールとして利用する場合は、Controllerなりの構造体を作成し、その中にgRPCのconnectionを入れるのが良い。global変数として使うと、変数定義時に死ぬ。\npackage main import ( ... \u0026#34;go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc\u0026#34; ) type Controller struct { conn *grpc.ClientConn } func main() { ... grpcHost := utils.GetEnv(\u0026#34;GRPC_HOST\u0026#34;, \u0026#34;localhost\u0026#34;) grpcPort := utils.GetEnv(\u0026#34;GRPC_PORT\u0026#34;, \u0026#34;50051\u0026#34;) conn, err := grpc.Dial(grpcHost+\u0026#34;:\u0026#34;+grpcPort, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()), ) defer conn.Close() c := Controller{conn: conn} ... }  (おまけ)otelhttpの利用  今回は標準ライブラリを用いて構築したので、otelhttpを利用する。これを使うことで、spanの作成や終了、メタデータの入れ込みなどを隠蔽できる。これを使う場合はオプションにotelhttp.WithPropagators(otel.GetTextMapPropagator())を追記しないといけない。 ただ実際はなくてもよかった。おそらくhttp送信する際にトレース情報を付与しているので、httpサーバ→httpサーバの場合は必要と思われる。ただし落としておく必要もないと思うのでそのままにする。\npackage main import ( ... ) func (c *Controller) userHandler(w http.ResponseWriter, r *http.Request) { ... } func main() { c := Controller{conn: conn} // otelhttp用のオプションが必要 \totelOptions := []otelhttp.Option{ otelhttp.WithTracerProvider(otel.GetTracerProvider()), otelhttp.WithPropagators(otel.GetTextMapPropagator()), } otelUserHandler := otelhttp.NewHandler( http.HandlerFunc(c.userHandler), \u0026#34;UserHandler\u0026#34;, otelOptions..., ) http.HandleFunc(\u0026#34;/\u0026#34;, otelUserHandler.ServeHTTP) fmt.Println(\u0026#34;start http server\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } サーバ側 gRPCサーバの構成方法は他の記事に譲るとして、、、\n TracerProviderの追加  大事なので2回書きますが、gRPCリクエスト受け取るサーバ側にもotel.SetTextMapPropagatorを追記すること。\npackage main import ( \u0026#34;go.opentelemetry.io/otel\u0026#34; \u0026#34;go.opentelemetry.io/otel/propagation\u0026#34; \u0026#34;github.com/lottotto/stdgrpc/utils\u0026#34; ) func main() { // tracerの設定 \ttp, err := utils.InitTraceProviderStdOut(\u0026#34;gRPC\u0026#34;, \u0026#34;1.0.0\u0026#34;) if err != nil { log.Fatalf(\u0026#34;something error: %v\u0026#34;, err) } otel.SetTracerProvider(tp) // 受け取る側にも必要→超ハマった \totel.SetTextMapPropagator( propagation.NewCompositeTextMapPropagator( propagation.TraceContext{}, propagation.Baggage{}, ), ) ... }  gRPCインターセプタの追加  gRPCクライアント側と同じように、サーバ側もgRPCのUnaryIntercepterにopentelemetry用のインターセプタを入れてあげます。\npackage main import ( ... \u0026#34;go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ... ) func main (){ lis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, 50051)) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } defer lis.Close() s := grpc.NewServer( grpc.UnaryInterceptor(otelgrpc.UnaryServerInterceptor()), ) ... }  SQL用のinstrumentationライブラリの追加  driverNameを追加し、otelsql用のドライバを作成する。その後そのdriverNameを利用してsqlのコネクションを開く。自分はマッピングの都合上、sqlxを使用した。database/sqlパッケージの互換だが、特にバグは出ずに使えている。本当に使っていいのかはもっと調査しなければならない。 これを追加することで、どのSQLクエリで実行されているかがトレースに出るようになった。ただし、実際のクエリパラメータは個人情報の問題起因で、出さないようにしている。\n(おまけ)こちらもgRPC通信のコネクションのように他プロセスでコネクションを共有し、コネクションプールとして利用するためには、main関数か何かでコネクションを作成、serverごとに構造体のフィールドとして持たせるのがよい。\npackage main import ( ... \u0026#34;github.com/jmoiron/sqlx\u0026#34; _ \u0026#34;github.com/lib/pq\u0026#34; semconv \u0026#34;go.opentelemetry.io/otel/semconv/v1.7.0\u0026#34; \u0026#34;github.com/XSAM/otelsql\u0026#34; ... ) func main(){ ... driverName, err := otelsql.Register(\u0026#34;postgres\u0026#34;, semconv.DBSystemPostgreSQL.Value.AsString()) if err != nil { log.Fatalf(\u0026#34;something error: %v\u0026#34;, err) } conn, err := sqlx.Open(driverName, utils.GetPostgresConnectionInfo()) if err != nil { log.Fatalf(\u0026#34;could not connect db: %v\u0026#34;, err) } defer conn.Close() ... } 結果 上記のような形で、db.statement部分に実行しているSQL文と、db.systemにPostgresという文字列が出力された。他にどのようなパラメータを出すべきかは、Githubにまとまっている。\n参考: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/semantic_conventions/database.md#call-level-attributes\nまとめ 結局自分で作り込むところは、TraceProvider部分とインターセプタとSQL接続するときのドライバ部分だけだった。今考えると簡単に実装できるのだと思う。実際の開発現場ではデータベースサーバの持ち主は、インフラを管理している舞台になると思うのでSQLを観れるのは良いと思う。またgRPC通信時にはどのようなトレースの情報を出すべきかについては考えないといけない。\n","permalink":"https://www.lottohub.jp/posts/otelsql-grpc/","summary":"モチベーション Go言語のOpentelemetryで適当なアプリにトレーシング機能をInstrumentation（計装）した際に、分割して","title":"Opentelemetryで基本的なトレーシングパターンを実装する"},{"content":"モチベーション Goの受け取ったデータを読んだり書いたりうまくできているのは、ReadメソッドとWriteメソッド、そしてどのメソッドを持つ、io.Reader、io.Writerといったインターフェースである。bytes.bufferをお題に色々忘れないようにメモしていく\nbyteとは 1バイトの範囲（1から255）を表すデータ型。 Go言語では、ファイル処理だったり、画像だったり、リクエストだったり色々な面で[]byteが出てくる。 もちろんstringも文字コードで表現されることから2バイトであるので、bytes型のスライスとして表現されることは多い。 []byteとstringの変換は下記の通り\n// []bytes -\u0026gt; string の変換 str := string([]bytes) // string -\u0026gt; []bytesの変換 b := []byte(str) このようにbyte型のスライスは頻出で簡単にstringに変換できる。このbyte型のスライスを色々簡単に操作できるようなパッケージがbytesパッケージになる。詳しくは公式ドキュメント参照。https://pkg.go.dev/byte\nbytesパッケージの中で2つだけ型が宣言されている.bytes.buffer型とreader型である。これをみていく\nbytes.bufferとは bytes.bufferとは、readメソッドとwriteメソッドを持つ可変サイズのバイトバッファーです。 色々おさらいしていきます。bufferとは基本的には、データを一時的に記憶する場所のことを言います。なのでその一時保存領域を読んだり、一時領域に書いたりすることができるわけです。\n// バッファからlen(p)サイズ文を読み取りpに格納する package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { str := \u0026#34;123456789\u0026#34; b := []byte(str) fmt.Println(b) b2 := []byte{0, 0} buf := bytes.NewBuffer(b) _, err := buf.Read(b2) if err != nil { panic(err) } // バッファからlen(p)サイズ文を読み取りpに格納する \tfmt.Println(string(b2)) } 実行すると12という結果が得られます。b2は2つの領域を定義しており、それが上書きされる挙動になっています。一方Writeの方は、\npackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { str := \u0026#34;123456789\u0026#34; b := []byte(str) fmt.Println(b) // :;を表すバイト配列 \tb2 := []byte{58, 59} buf := bytes.NewBuffer(b) _, err := buf.Write(b2) if err != nil { panic(err) } fmt.Println(string(b2)) // 一時領域を文字列に変換 \tfmt.Println(buf.String()) } 上記のプログラムの実行結果としては、123456789:;が得られます。b2に定義していた内容が、byte.bufferの内部領域に付け加えられ、文字列変換時に標準出力に出てきます。\nこんな感じでbytes.buffer型は中にデータを可変長として持ち、入力であるバイトのスライスに対して、読み込み結果を入れるReadメソッドとスライスの内容を書き込むWriteメソッドがあり、配列のサイズなど考えずに操作可能になります。 このReadメソッドとWriteメソッドを持つということ、つまり、io.Readerとio.Writerというインターフェースで利用できるというのがGo言語で強みになっていきます。\n","permalink":"https://www.lottohub.jp/posts/go-bytebuffer/","summary":"モチベーション Goの受け取ったデータを読んだり書いたりうまくできているのは、ReadメソッドとWriteメソッド、そしてどのメソッドを持つ、","title":"go言語のbyte.bufferについて"},{"content":"Profile 若手のシステムエンジニア。アプリと基盤チームがこぼれがちな領域で食べています。例えばコンテナ、CICD、Observabilityあたりが得意領域のつもり。最近はクラウドも。\nめも どうせ続かないと思うのですが、調べた内容などを忘れないようにするためにHugo と Github Pageを利用してブログ的な何かを始めてみました。素人が書いた内容なので、間違った部分やアプデにより解消された部分もあります。その時はご指摘いただけると助かります。\n","permalink":"https://www.lottohub.jp/about/","summary":"Profile 若手のシステムエンジニア。アプリと基盤チームがこぼれがちな領域で食べています。例えばコンテナ、CICD、Observabilityあたりが","title":"aboutme"},{"content":"bazelとは ソースコードをコンパイルして、実行可能形式にしたり、テストをしたりする一連の処理をまとめてやってくれるツールのことをビルドツールと言い、例えばMake,Maven, Gradleなどがある。 もともとgoogle ではBlazeというビルドツールが利用されていて、これをOSS化したのがbazelになる\nbazelの特徴   多言語サポート\n Bazelは多くの言語をサポートしており、任意のプログラミング言語をサポートするように拡張可能。    高レベルのビルド言語\n プロジェクトはBUILDファイルにてで記述。BUILDファイル相互接続された小さなライブラリ、バイナリ、およびテストのセットとしてプロジェクトを記述する簡潔なテキスト形式。対照的に、Makeのようなツールでは、個々のファイルとコンパイラの呼び出しを記述する必要があります。    マルチプラットフォームのサポート\n 同じツールと同じBUILDファイルを使用して、さまざまなアーキテクチャ、さらにはさまざまなプラットフォーム用のソフトウェアを構築可能 GoogleではBazelを使用してデータセンターのシステムで実行されるサーバーアプリケーションから携帯電話で実行されるクライアントアプリまで、あらゆるものを構築。    再現性\n BUILDファイルでは、各ライブラリ、テスト、およびバイナリで直接の依存関係を完全に指定する必要があるため、Bazelはこの依存関係情報を使用して、ソースファイルに変更を加えたときに何を再構築する必要があるか、およびどのタスクを並行して実行できるかを認識。 これはすべてのビルドが常に同じ結果を生成することを意味します。    スケーラブル\n Bazelは大規模なビルドを処理可能。 Googleでは、サーバーバイナリに10万のソースファイルがあるのが一般的であり、ファイルが変更されていないビルドには約200ミリ秒かかかるらしい    Googleはなぜbazelを利用するのか  Makeの場合  人力でMakefileを書くのは結構辛い   Mavenの場合  Javaだけなのが辛い Bazelではコードを再利用可能な単位に細分化することを推奨しており、差分だけをビルドするといったことが可能なので   gradleの場合  Gradleの設定ファイルが読みづらいのが辛い Bazelは各アクションが何を行うかを正確に理解できるのでより並列化され、より再現性が高くなるらしい    gradle 陣営はbazelを使うとBUILDファイルがめちゃくちゃ増えることなどで管理コストが増大することを理由に反論しています 参考: https://blog.gradle.org/gradle-vs-bazel-jvm\n対応言語やフレームワーク https://awesomebazel.com/ ほとんど一般的な言語やフレームワークは対応していそうですね。\n実際にどのような会社やOSSがbazelを使用しているのか https://bazel.build/users.html に書いてあるが気になった部分を書きます。\n 日本企業が少ない。  2022/01/15現在、LINEだけしかない。まだまだ日本でbazelが受けいられていない状態かなと思っています   KubernetesはBazelビルドから脱却したみたい  どうやらKubernetesではビルドが煩雑で大変だったのをmakeに統一したようです。 https://github.com/kubernetes/enhancements/issues/2420 https://github.com/kubernetes/kubernetes/issues/88553 基本ほとんどがGoで書かれているので、まあbazelのおいしさを完全に享受できるとは思わないです。    インストール方法 自分はMacを使用したのでMacでの説明になります 参考: https://docs.bazel.build/versions/4.2.2/install-os-x.html\nexport BAZEL_VERSION=3.2.0 curl -fLO \u0026#34;https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh\u0026#34; # 実行権限をつけて実行 chmod +x \u0026#34;bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh\u0026#34; ./bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh --user user@usernoMacBook-Pro tmp % ./bazel-${BAZEL_VERSION}-installer-darwin-x86_64.sh --user Bazel installer --------------- Bazel is bundled with software licensed under the GPLv2 with Classpath exception. You can find the sources next to the installer on our release page: https://github.com/bazelbuild/bazel/releases # setting authenticate proxy # Binary package at HEAD (@15371720ae0c4) - [Commit](https://github.com/bazelbuild/bazel/commit/15371720ae0c4) Uncompressing......Extracting Bazel installation... . Bazel is now installed! Make sure you have \u0026quot;/Users/user/bin\u0026quot; in your path. For bash completion, add the following line to your : source /Users/user/.bazel/bin/bazel-complete.bash For fish shell completion, link this file into your /Users/user/.config/fish/completions/ directory: ln -s /Users/user/.bazel/bin/bazel.fish /Users/user/.config/fish/completions/bazel.fish See http://bazel.build/docs/getting-started.html to start a new project! bazelの始め方  WORKSPACEファイルの用意  bazelにおけるワークスペースとは、ビルドするソフトウェアのソースファイルとビルド出力先を含むディレクトリ.各ワークスペースごとにはWORKSPACEというテキストファイルがあり、空も場合もあれば、外部依存関係への参照が含まれている. つまりプロジェクトのルートにはWORKSPACEがあればOK   BUILDファイルの用意  Starlarkという言語を利用して、ビルドターゲットを指定することでBUILDファイルを記述.  java_binary( name = \u0026quot;ProjectRunner\u0026quot;, srcs = [\u0026quot;src/main/java/com/example/ProjectRunner.java\u0026quot;], main_class = \u0026quot;com.example.ProjectRunner\u0026quot;, deps = [\u0026quot;:greeter\u0026quot;], ) java_library( name = \u0026quot;greeter\u0026quot;, srcs = [\u0026quot;src/main/java/com/example/Greeting.java\u0026quot;], )  Bazelがビルドするソースコードとその依存関係、そしてbazelが利用するビルドルールなどが記載される   ビルドする  bazel build //path/to/package:\u0026lt;ビルドターゲット名\u0026gt;でビルド可能  user@usernoMacBook-Pro java-tutorial % bazel build //:ProjectRunner INFO: Analyzed target //:ProjectRunner (0 packages loaded, 0 targets configured). INFO: Found 1 target... Target //:ProjectRunner up-to-date: bazel-bin/ProjectRunner.jar bazel-bin/ProjectRunner INFO: Elapsed time: 0.431s, Critical Path: 0.01s INFO: 1 process: 1 internal. INFO: Build completed successfully, 1 total action   サンプルプロジェクトの解説 対象プロジェクトは https://github.com/bazelbuild/examples/tree/main/java-tutorial\nワークスペースの立ち上げ WORKSPACEファイルには外部依存関係が記載されます。本プロジェクトでは特に外部参照の依存関係についてないので、空欄のままです。\nBUILD ファイルの理解 例えば下記のビルドファイルでは、java_binaryというルールがProjectRunnerという名前で作成されています。\njava_binary( name = \u0026#34;ProjectRunner\u0026#34;, srcs = glob([\u0026#34;src/main/java/com/example/*.java\u0026#34;]), ) 公式ドキュメントのJavaRulesを参照すると、\n Builds a Java archive (\u0026ldquo;jar file\u0026rdquo;), plus a wrapper shell script with the same name as the rule. The wrapper shell script uses a classpath that includes, among other things, a jar file for each library on which the binary depends.\n つまり、java_binaryコマンドは、jarと同名のラッパースクリプトを作成するルールのようです。\nプロジェクトのビルド 上記のBUILDファイルの元でビルドするコマンドは下記になります。/はWORKSPACEと同じ階層にあるBUILDファイルを示しています。\n$ bazel build //:ProjectRunner 依存関係のグラフを出力 このコマンドを実行すること\n$ bazel query --notool_deps --noimplicit_deps \u0026quot;deps(//:ProjectRunner)\u0026quot; --output graph digraph mygraph { node [shape=box]; \u0026quot;//:ProjectRunner\u0026quot; \u0026quot;//:ProjectRunner\u0026quot; -\u0026gt; \u0026quot;//:src/main/java/com/example/Greeting.java\\n//:src/main/java/com/example/ProjectRunner.java\u0026quot; \u0026quot;//:src/main/java/com/example/Greeting.java\\n//:src/main/java/com/example/ProjectRunner.java\u0026quot; } こんな感じの依存関係を出すことができます。今回のプロジェクトでは簡単なので役に立たないですが、複雑になってくると便利かと思います。\nもちろんgradleにも同じ機能はあります。\nbazelビルドを改良する ここからbazelビルドを改良して、モジュールを切り出します。\nload(\u0026#34;@rules_java//java:defs.bzl\u0026#34;, \u0026#34;java_binary\u0026#34;) java_binary( name = \u0026#34;ProjectRunner\u0026#34;, srcs = [\u0026#34;src/main/java/com/example/ProjectRunner.java\u0026#34;], main_class = \u0026#34;com.example.ProjectRunner\u0026#34;, deps = [\u0026#34;:greeter\u0026#34;], ) java_library( name = \u0026#34;greeter\u0026#34;, srcs = [\u0026#34;src/main/java/com/example/Greeting.java\u0026#34;], ) java_binaryのところで2つ出てきました。こちらも公式ドキュメントに書いてあるのですが、main_classはエントリーポイントとなるmain()関数を持っているクラスを指定しています。deps部分は依存しているルールターゲット名になります。\nbazel build //:ProjectRunner これによって、java_binary(ProjectRunner)とjava_library(greeter)が実行され、それぞれProjectRunner.jarとlibgreeter.jarが作成されました。 依存関係の図も出してみると想像した通り、greeterへの依存関係が追加されています。\n$ bazel query --notool_deps --noimplicit_deps \u0026#34;deps(//:ProjectRunner)\u0026#34; --output graph digraph mygraph { node [shape=box]; \u0026#34;//:ProjectRunner\u0026#34; \u0026#34;//:ProjectRunner\u0026#34; -\u0026gt; \u0026#34;//:greeter\u0026#34; \u0026#34;//:ProjectRunner\u0026#34; -\u0026gt; \u0026#34;//:src/main/java/com/example/ProjectRunner.java\u0026#34; \u0026#34;//:src/main/java/com/example/ProjectRunner.java\u0026#34; \u0026#34;//:greeter\u0026#34; \u0026#34;//:greeter\u0026#34; -\u0026gt; \u0026#34;//:src/main/java/com/example/Greeting.java\u0026#34; \u0026#34;//:src/main/java/com/example/Greeting.java\u0026#34; } Javaの推移的依存関係について ビルドツールの鬼門といえば推移的依存関係です。推移的依存関係とは、ライブラリAがライブラリBに依存していて、ライブラリBがライブラリCに依存していることを言います。bazelにおける推移的依存関係を解決するにはrules_jvm_externalを使えばOKだそうです。使い方はWORKSPACEに記載すればOKです\n参考: https://blog.bazel.build/2019/03/31/rules-jvm-external-maven.html\nload(\u0026#34;@bazel_tools//tools/build_defs/repo:http.bzl\u0026#34;, \u0026#34;http_archive\u0026#34;) http_archive( name = \u0026#34;rules_jvm_external\u0026#34;, strip_prefix = \u0026#34;rules_jvm_external-1.2\u0026#34;, sha256 = \u0026#34;e5c68b87f750309a79f59c2b69ead5c3221ffa54ff9496306937bfa1c9c8c86b\u0026#34;, url = \u0026#34;https://github.com/bazelbuild/rules_jvm_external/archive/1.2.zip\u0026#34; ) その後BUILDファイルに、上記のrules_jvm_externalをloadした上でmaven_installルールを記載します。\nload(\u0026#34;@rules_jvm_external//:defs.bzl\u0026#34;, \u0026#34;maven_install\u0026#34;) maven_install( name = \u0026#34;maven\u0026#34;, artifacts = [ \u0026#34;androidx.test.espresso:espresso-core:3.1.1\u0026#34;, \u0026#34;com.google.guava:guava:27.0-android\u0026#34;, ], repositories = [ \u0026#34;https://maven.google.com\u0026#34;, \u0026#34;https://repo1.maven.org/maven2\u0026#34;, ], fetch_sources = True, # Fetch source jars. Defaults to False. ) またこのmaven_installでは、推移的依存関係が衝突したときユーザーで指定できるようになっています。version_conflict_policy=\u0026quot;pinned\u0026quot;と記載することで、明記されたものを使うことができるようです。ただめちゃくちゃ書くのが辛そうですね。 https://github.com/bazelbuild/rules_jvm_external#resolving-user-specified-and-transitive-dependency-version-conflicts\nGo言語でBazelを利用する場合 今度まとめてみたいとおもいます。下記参考先を読む限り、gazelleといったものを使うことでBUILDファイルを自動生成できるのが良いということでした。\n参考: https://note.crohaco.net/2020/bazel-golang/\n考察 ここからbazelがじゃあ使えるかどうかというのを考えていきます。気になったポイントとしては2点です。\nBazelが役に立つのは、モノリポかつシステムのポリグロット化進んだ時になるのではないか。 bazelが強いところは、多言語多フレームワーク対応しているところと考えています。多言語多フレームワークをビルドするには環境構築がかなり大変なので、bazel一つ用意すればビルドできるようになるというのはとても便利だと思います。また書くパッケージごとにBUILDファイルがあるため、差分ビルドが容易にできると思います。パイプラインのこのファイルが変更されたらこのコマンドを実行するといった制御を実施することで、ビルドが高速化されそうですね。そして、この細かく制御したい、他のビルドも同時にしたいというのは、ポリグロット(多言語)かつモノリポジドリで運用しているが前提になるのかなと・・・。これができている組織ってかなり少ないと思います。\nDockerまわりなどは標準のやり方の方が理解しやすく、また参考文献も少なく学習コストが高い。 Dockerビルドのものを見てみましたが、DockerFileを使ったビルドの方がどうしてもやりやすそうです。このような文献も少なく、どうしても学習コストが高いものになってしまうのでしょうか。学習コストが高くなった結果、ビルドおじさんといったそういう専門家が必要になるのではないでしょうか。実際Kubernetesでは、go標準のビルドが短時間になった結果、makeとbazelを両立して管理する必要なくないかということになり、Makeに統一されました。もちろん理由の一つとしてGoのエコシステムではbazelが一般的ではなく、利用する人やコントリビュータを取り込むのに弊害になりそうということもあります\nまとめ  bazelは多言語対応だったりビルドを細かくする仕組みがあり、機能としては高い。 しかし、前提としてモノリポやポリグロット化されていることが前提であり、それを一般的に利用できている組織はまだないのではないか。 今後googleようなリポジトリ構成が一般的になる可能性はあるので、しばらくはgradleや言語の標準ビルドツールで良いかと思うが、ウオッチして損はないのではないか。  ","permalink":"https://www.lottohub.jp/posts/bazel/","summary":"bazelとは ソースコードをコンパイルして、実行可能形式にしたり、テストをしたりする一連の処理をまとめてやってくれるツールのことをビルドツー","title":"bazel触ってみた"}]